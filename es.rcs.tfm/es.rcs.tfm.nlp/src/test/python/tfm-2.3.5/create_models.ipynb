{
 "cells": [
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Creates Tensorflow Graphs for spark-nlp DL Annotators and Models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "/home/dukegris/Workspace-TFM/TFM/es.rcs.tfm/es.rcs.tfm.nlp/src/main/python/tfm\n"
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'ner_model'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-ae982b6dcf07>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpathlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mner_model\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNerModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdataset_encoder\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDatasetEncoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mner_model_saver\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNerModelSaver\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'ner_model'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "try:\n",
    "\tos.chdir(os.path.join(os.getcwd(), '/home/rcuesta/TFM/es.rcs.tfm/es.rcs.tfm.nlp/src/main/python/tfm'))\n",
    "\tprint(os.getcwd())\n",
    "except:\n",
    "\tpass\n",
    "    \n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import string\n",
    "import random\n",
    "import math\n",
    "import sys\n",
    "import shutil\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from ner_model import NerModel\n",
    "from dataset_encoder import DatasetEncoder\n",
    "from ner_model_saver import NerModelSaver\n",
    "\n",
    "CORPUS_PATH=\"/home/rcuesta/TFM/es.rcs.tfm/es.rcs.tfm.corpus/\"\n",
    "DATASET_PATH=CORPUS_PATH + \"datasets/\"\n",
    "BERT_PATH=DATASET_PATH + 'bert/'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_contrib = False if os.name == 'nt' else True\n",
    "\n",
    "name_prefix = 'blstm-noncontrib' if not use_contrib else 'blstm'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_graph(ntags, embeddings_dim, nchars, lstm_size = 128):\n",
    "    #RCS if sys.version_info[0] != 3 or sys.version_info[1] >= 7:\n",
    "    if sys.version_info[0] != 3 or sys.version_info[1] >= 9:\n",
    "        print('Python 3.7 or above not supported by tensorflow')\n",
    "        return\n",
    "    #RCS if tf.__version__ != '1.12.0':\n",
    "    if tf.__version__ != '1.13.2':\n",
    "        print('Spark NLP is compiled with Tensorflo 1.12.0. Please use such version.')\n",
    "        return\n",
    "\n",
    "    tf.reset_default_graph()\n",
    "    model_name = name_prefix+'_{}_{}_{}_{}'.format(ntags, embeddings_dim, lstm_size, nchars)\n",
    "    with tf.Session() as session:\n",
    "        ner = NerModel(session=None, use_contrib=use_contrib)\n",
    "        ner.add_cnn_char_repr(nchars, 25, 30)\n",
    "        ner.add_bilstm_char_repr(nchars, 25, 30)\n",
    "        ner.add_pretrained_word_embeddings(embeddings_dim)\n",
    "        ner.add_context_repr(ntags, lstm_size, 3)\n",
    "        ner.add_inference_layer(True)\n",
    "        ner.add_training_op(5)\n",
    "        ner.init_variables()\n",
    "        saver = tf.train.Saver()\n",
    "        file_name = model_name + '.pb'\n",
    "        tf.train.write_graph(ner.session.graph, BERT_PATH, file_name, False)\n",
    "        ner.close()\n",
    "        session.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Attributes info\n",
    "- 1st attribute: max number of tags (Must be at least equal to the number of unique labels, including O if IOB)\n",
    "- 2nd attribute: embeddings dimension\n",
    "- 3rd attribute: max number of characters processed (Must be at least the largest possible amount of characters)\n",
    "- 4th attribute: LSTM Size (128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_graph(14, 1024, 62)\n",
    "#create_graph(80, 200, 125)\n",
    "# create_graph(10, 200, 100)\n",
    "# create_graph(10, 300, 100)\n",
    "# create_graph(10, 768, 100)\n",
    "# create_graph(10, 1024, 100)\n",
    "# create_graph(25, 300, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.__version__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}