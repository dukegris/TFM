{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rcuesta/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/rcuesta/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/rcuesta/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/rcuesta/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/rcuesta/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/rcuesta/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import shutil\n",
    "\n",
    "from embeddings_resolver import BertEmbeddingsResolver\n",
    "from ner_model_saver import NerModelSaver\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "from sparknlp.annotator import *\n",
    "from sparknlp.common import *\n",
    "from sparknlp.base import *\n",
    "from sparknlp.embeddings import *\n",
    "import sparknlp \n",
    "\n",
    "import time\n",
    "import zipfile\n",
    "\n",
    "CORPUS_PATH=\"../../../../es.rcs.tfm.corpus/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark NLP version\n",
      "2.2.0\n",
      "Apache Spark version\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2.4.3'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark = sparknlp.start()\n",
    "\n",
    "print(\"Spark NLP version\")\n",
    "sparknlp.version()\n",
    "print(\"Apache Spark version\")\n",
    "spark.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_model(url, name):\n",
    "    import os\n",
    "    from pathlib import Path\n",
    "    import urllib.request\n",
    "    import zipfile\n",
    "    zip_file = CORPUS_PATH + 'training/test/' + name + \".zip\"\n",
    "    if not Path(zip_file).is_file():\n",
    "        print(\"Downloading \" + url)\n",
    "        urllib.request.urlretrieve(url, zip_file)\n",
    "    if not os.path.exists(CORPUS_PATH + 'training/bert/' + name):\n",
    "        print(\"Unziping \")\n",
    "        zip_ref = zipfile.ZipFile(zip_file, 'r')\n",
    "        zip_ref.extractall(CORPUS_PATH + 'training/bert/')\n",
    "        zip_ref.close()\n",
    "\n",
    "\n",
    "def get_service_token_ids(source_bert_folder):\n",
    "    start_id = 0\n",
    "    end_id = 0\n",
    "    with open(os.path.join(source_bert_folder, \"vocab.txt\")) as f:\n",
    "        for line, row in enumerate(f):\n",
    "            row = row.strip()\n",
    "            if row == '[CLS]':\n",
    "                start_id = line\n",
    "            if row == '[SEP]':\n",
    "                end_id = line\n",
    "    return (start_id, end_id)\n",
    "\n",
    "\n",
    "def create_model(source_bert_folder, export_dir, max_sentence_length = 128, batch_size = 32):\n",
    "    tf.reset_default_graph()\n",
    "    is_cased = 'uncased' not in source_bert_folder.lower()\n",
    "    print(\"source_bert_folder: {}\".format(source_bert_folder))\n",
    "    print(\"is_cased: {}\".format(is_cased))\n",
    "    print(\"lowercase: {}\".format(not is_cased))\n",
    "    resolver = BertEmbeddingsResolver(source_bert_folder, max_sentence_length, lowercase = not is_cased)\n",
    "    saver = NerModelSaver(resolver, None)\n",
    "    saver.save_models(export_dir)\n",
    "    resolver.session.close()\n",
    "    shutil.copyfile(os.path.join(source_bert_folder, 'vocab.txt'),\n",
    "                    os.path.join(export_dir, 'vocab.txt'))\n",
    "\n",
    "    dim = resolver.config.hidden_size\n",
    "    layers = resolver.config.num_hidden_layers\n",
    "    print(\"Number of hidden units: {}\".format(dim))\n",
    "    print(\"Number of layers: {}\".format(layers))\n",
    "    \n",
    "    model = BertEmbeddings.loadFromPython(export_dir, spark) \\\n",
    "        .setInputCols([\"sentence\", \"token\"]) \\\n",
    "        .setOutputCol(\"embeddings\") \\\n",
    "        .setMaxSentenceLength(max_sentence_length) \\\n",
    "        .setBatchSize(batch_size) \\\n",
    "        .setDimension(dim) \\\n",
    "        .setCaseSensitive(is_cased)\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def download_and_convert(url, name, max_sentence_length = 128, batch_size = 32, dst_folder = CORPUS_PATH + 'models/bert'):\n",
    "    if not os.path.exists(dst_folder):\n",
    "        os.makedirs(dst_folder)\n",
    "    download_model(url, name)\n",
    "    model = create_model(CORPUS_PATH + 'training/bert/' + name, CORPUS_PATH + 'training/bert/' + name + '_export_dir', max_sentence_length, batch_size)\n",
    "    # Remove but it's possible to use this model\n",
    "    shutil.rmtree(CORPUS_PATH + 'training/bert/' + name + '_export_dir')\n",
    "    # shutil.rmtree(name)\n",
    "    final_model_name = name + '_M-{}'.format(max_sentence_length) + '_B-{}'.format(batch_size)\n",
    "    model.write().overwrite().save(os.path.join(dst_folder, final_model_name))\n",
    "    print(\"BERT model has been saved: {}\".format(dst_folder+'/'+final_model_name))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find models and source code here https://github.com/google-research/bert "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://storage.googleapis.com/bert_models/2018_10_18/uncased_L-12_H-768_A-12.zip\n",
      "Unziping \n",
      "source_bert_folder: uncased_L-12_H-768_A-12\n",
      "is_cased: False\n",
      "lowercase: True\n",
      "INFO:tensorflow:Restoring parameters from uncased_L-12_H-768_A-12/bert_model.ckpt\n",
      "Number of hidden units: 768\n",
      "Number of layers: 12\n"
     ]
    }
   ],
   "source": [
    "# 1. Base uncased\n",
    "url = 'https://storage.googleapis.com/bert_models/2018_10_18/uncased_L-12_H-768_A-12.zip'\n",
    "name = 'uncased_L-12_H-768_A-12'\n",
    "download_and_convert(url, name, max_sentence_length = 128, batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Large uncased\n",
    "url = 'https://storage.googleapis.com/bert_models/2018_10_18/uncased_L-24_H-1024_A-16.zip'\n",
    "name = 'uncased_L-24_H-1024_A-16'\n",
    "download_and_convert(url, name, max_sentence_length = 128, batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unziping \n",
      "source_bert_folder: ../../../../es.rcs.tfm.corpus/training/test/cased_L-12_H-768_A-12\n",
      "is_cased: True\n",
      "lowercase: False\n",
      "INFO:tensorflow:Restoring parameters from ../../../../es.rcs.tfm.corpus/training/test/cased_L-12_H-768_A-12/bert_model.ckpt\n",
      "Number of hidden units: 768\n",
      "Number of layers: 12\n",
      "BERT model has been saved: ../../../../es.rcs.tfm.corpus/models/test/cased_L-12_H-768_A-12_M-128_B-32\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BERT_EMBEDDINGS_dfaabcfcf440"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3. Base cased\n",
    "url = 'https://storage.googleapis.com/bert_models/2018_10_18/cased_L-12_H-768_A-12.zip'\n",
    "name = 'cased_L-12_H-768_A-12'\n",
    "download_and_convert(url, name, max_sentence_length = 128, batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Large cased\n",
    "url = 'https://storage.googleapis.com/bert_models/2018_10_18/cased_L-24_H-1024_A-16.zip'\n",
    "name = 'cased_L-24_H-1024_A-16'\n",
    "download_and_convert(url, name, max_sentence_length = 128, batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Multilingual Cased (New, recommended)\n",
    "url = 'https://storage.googleapis.com/bert_models/2018_11_23/multi_cased_L-12_H-768_A-12.zip'\n",
    "name = 'multi_cased_L-12_H-768_A-12'\n",
    "download_and_convert(url, name, max_sentence_length = 128, batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Large uncased\n",
    "url = 'https://storage.googleapis.com/bert_models/2019_05_30/wwm_uncased_L-24_H-1024_A-16.zip'\n",
    "name = 'wwm_uncased_L-24_H-1024_A-16'\n",
    "download_and_convert(url, name, max_sentence_length = 128, batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Large cased\n",
    "url = 'https://storage.googleapis.com/bert_models/2019_05_30/wwm_cased_L-24_H-1024_A-16.zip'\n",
    "name = 'wwm_cased_L-24_H-1024_A-16'\n",
    "download_and_convert(url, name, max_sentence_length = 128, batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('All generated models are inside \"models/\" directory')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(name, max_sentence_length = 128, batch_size = 32, dst_folder = CORPUS_PATH + 'models/bert'):\n",
    "    if not os.path.exists(dst_folder):\n",
    "        os.makedirs(dst_folder)\n",
    "    model = create_model(CORPUS_PATH + 'datasets/biobert/' + name, CORPUS_PATH + 'training/bert/' + name + '_export_dir', max_sentence_length, batch_size)\n",
    "    # Remove but it's possible to use this model\n",
    "    shutil.rmtree(CORPUS_PATH + 'training/bert/' + name + '_export_dir')\n",
    "    final_model_name = name + '_M-{}'.format(max_sentence_length) + '_B-{}'.format(batch_size)\n",
    "    model.write().overwrite().save(os.path.join(dst_folder, final_model_name))\n",
    "    print(\"BERT model has been saved: {}\".format(dst_folder+'/'+final_model_name))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find models in: \n",
    "GOOGLE: https://github.com/google-research/bert\n",
    "\n",
    "BIOBERT: https://github.com/naver/biobert-pretrained/releases\n",
    "\n",
    "Dependiendo del nombre ocurren varias cosas:\n",
    "\n",
    "- Busca la cadena uncased en el nombre para establecer si el modelo es uncased\n",
    "- embeddings_resolver.py requiere que el modelo se denomine internamente bert_model.ckpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source_bert_folder: ../../../../es.rcs.tfm.corpus/datasets/biobert/biobert_v1.1_pubmed_bert\n",
      "is_cased: True\n",
      "lowercase: False\n",
      "INFO:tensorflow:Restoring parameters from ../../../../es.rcs.tfm.corpus/datasets/biobert/biobert_v1.1_pubmed_bert/bert_model.ckpt\n",
      "Number of hidden units: 768\n",
      "Number of layers: 12\n",
      "BERT model has been saved: ../../../../es.rcs.tfm.corpus/models/test/biobert_v1.1_pubmed_bert_M-128_B-32\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BERT_EMBEDDINGS_66651538929c"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name = 'biobert_v1.1_pubmed_bert'\n",
    "convert(name, max_sentence_length = 128, batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
