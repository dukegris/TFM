FROM clearlinux:latest AS tfm_os_builder

LABEL maintainer "Raul Cuesta <raul.cuesta.sainz@gmail.com>"
LABEL repository "https://github.com/dukegris/TFM"

ARG swupd_args

# Move to latest Clear Linux release to ensure
# that the swupd command line arguments are
# correct
RUN swupd clean
RUN swupd update --no-boot-update $swupd_args

# Utilities for the setup
RUN swupd bundle-add curl \
  --debug \
  --no-progress \
  --no-boot-update

WORKDIR /usr/local

# Download SCALA and install the necesary files in target directory 'install-root',
# using the new os version
ARG SCALA_VERSION="2.11.12"
ARG SCALA_URL="https://downloads.lightbend.com/scala/$SCALA_VERSION/scala-$SCALA_VERSION.tgz"
RUN /usr/bin/curl "$SCALA_URL" --insecure --output scala.tgz

# Download HADOOP and install the necesary files in target directory 'install-root',
# using the new os version
ARG HADOOP_VERSION="2.7.7"
ARG HADOOP_CLOSER_URL="http://www.apache.org/dyn/closer.lua?filename=hadoop/core/hadoop-$HADOOP_VERSION/hadoop-$HADOOP_VERSION.tar.gz&action=download"
ARG HADOOP_DIST_URL="https://www.apache.org/dist/hadoop/core/hadoop-$HADOOP_VERSION/hadoop-$HADOOP_VERSION.tar.gz"
ARG HADOOP_ARCHIVE_URL="https://archive.apache.org/dist/hadoop/core/hadoop-$HADOOP_VERSION/hadoop-$HADOOP_VERSION.tar.gz"
RUN /usr/bin/curl "$HADOOP_ARCHIVE_URL" --insecure --output hadoop.tgz

# Download SPARK and install the necesary files in target directory 'install-root',
# using the new os version
ARG SPARK_VERSION="2.4.6"
ARG SPARK_CLOSER_URL="http://www.apache.org/dyn/closer.lua?filename=spark/spark-$SPARK_VERSION/spark-$SPARK_VERSION-bin-without-hadoop.tgz&action=download"
ARG SPARK_DIST_URL="https://www.apache.org/dist/spark/spark-$SPARK_VERSION/spark-$SPARK_VERSION-bin-without-hadoop.tgz"
ARG SPARK_ARCHIVE_URL="https://archive.apache.org/dist/spark/spark-$SPARK_VERSION/spark-$SPARK_VERSION-bin-without-hadoop.tgz"
RUN /usr/bin/curl "$SPARK_ARCHIVE_URL" --insecure --output spark.tgz

# Grab os-release info from the minimal base image so
# that the new content matches the exact OS version
COPY --from=clearlinux/os-core:latest /usr/lib/os-release /

# Install clean os-core bundle in target directory 'install-root'
# using the new os version
RUN source /os-release && \
  mkdir /install-root && \
  swupd os-install \
  -V ${VERSION_ID} \
  --debug \
  --no-progress \
  --path /install-root \
  --statedir /swupd-state \
  --no-boot-update \
  --bundles=os-core,locales,java-runtime
#	--bundles=os-core,os-core-plus,locales,curl,which,java11-basic

# SCALA
RUN tar xf /usr/local/scala.tgz --directory /install-root/usr/local &&\
  mv /install-root/usr/local/scala-$SCALA_VERSION /install-root/usr/local/scala

# HADOOP
RUN tar xf /usr/local/hadoop.tgz --directory /install-root/usr/local &&\
  mv /install-root/usr/local/hadoop-$HADOOP_VERSION /install-root/usr/local/hadoop

# SPARK
RUN tar xf /usr/local/spark.tgz --directory /install-root/usr/local &&\
  mv /install-root/usr/local/spark-$SPARK_VERSION-bin-without-hadoop /install-root/usr/local/spark &&\
  mv /install-root/usr/local/spark/conf/spark-env.sh.template /install-root/usr/local/spark/conf/spark-env.sh &&\
  echo "export SPARK_DIST_CLASSPATH=\$(hadoop classpath)" >> /install-root/usr/local/spark/conf/spark-env.sh

# For some Host OS configuration with redirect_dir on,
# extra data are saved on the upper layer when the same
# file exists on different layers. To minimize docker
# image size, remove the overlapped files before copy.
RUN mkdir /os-core-install
COPY --from=clearlinux/os-core:latest / /os-core-install/
RUN cd / && \
  find os-core-install | \
  sed -e 's/os-core-install/install-root/' | \
  xargs rm -d &> /dev/null || true

# Copy the updated lastest version on the target system to the root,
# Forgot the base and execute a cleaned flaten image
FROM clearlinux/os-core:latest
COPY --from=tfm_os_builder /install-root /

# SPARK
ARG TFM_USER="tfm"
ARG TFM_GROUP="tfm"
ARG TFM_BIN_DIR="/usr/local/spark"
ARG TFM_RUN_DIR="/run/spark"
ARG TFM_ETC_DIR="/var/etc/spark"
ARG TFM_LOGS_DIR="/var/log/spark"
ARG TFM_METADATA_DIR="/var/lib/spark"
ARG TFM_DATA_DIR="/var/lib/tfm"

RUN groupadd -r $TFM_GROUP &&\
  useradd --no-log-init -r -g $TFM_GROUP $TFM_USER &&\
  mkdir -p $TFM_LOGS_DIR &&\
  mkdir -p $TFM_RUN_DIR &&\
  mkdir -p $TFM_METADATA_DIR &&\
  mkdir -p $TFM_DATA_DIR &&\
  chown -R $TFM_USER:$TFM_GROUP $TFM_BIN_DIR &&\
  chown -R $TFM_USER:$TFM_GROUP $TFM_LOGS_DIR &&\
  chown -R $TFM_USER:$TFM_GROUP $TFM_RUN_DIR &&\
  chown -R $TFM_USER:$TFM_GROUP $TFM_METADATA_DIR &&\
  chown -R $TFM_USER:$TFM_GROUP $TFM_DATA_DIR &&\
  chmod 700 "$TFM_LOGS_DIR" &&\
  chmod 700 "$TFM_RUN_DIR" &&\
  chmod 700 "$TFM_METADATA_DIR" &&\
  chmod 700 "$TFM_DATA_DIR"

USER $TFM_USER

# OS LOCALES
ENV TZ=Europe/Madrid \
  LANGUAGE=en_US:en \
  LC_ALL=en_US.UTF-8 \
  LANG=en_US.UTF-8

ENV JAVA_HOME=/usr/lib/jvm/java-1.8.0-openjdk \
  SCALA_HOME=/usr/local/scala \
  HADOOP_HOME=/usr/local/hadoop \
  HADOOP_CONF_DIR=/usr/local/hadoop/etc \
  HADOOP_LIBEXEC_DIR=/usr/local/hadoop/libexec \
  SPARK_HOME=/usr/local/spark \
  SPARK_CONF_DIR=/usr/local/spark/conf \
  SPARK_PID_DIR=/run/spark \
  SPARK_LOG_DIR=/var/log/spark \
  SPARK_MASTER_PORT=7077 \
  SPARK_MASTER_WEBUI_PORT=8080 \
  SPARK_WORKER_PORT=7077 \
  SPARK_WORKER_WEBUI_PORT=8080 \
  SPARK_WORKER_DIR=/var/lib/spark \
  SPARK_MASTER_URL=$TFM_MASTER_URL \
  LD_LIBRARY_PATH=$LD_LIBRARY_PATH:$HADOOP_HOME/lib/native \
  PATH=$SCALA_HOME/bin:$HADOOP_HOME/bin:$HADOOP_HOME/sbin:$SPARK_HOME/sbin:$SPARK_HOME/bin:$PATH

# APPLICATION
ARG TFM_MASTER_URL="spark://spark_master:7077"

EXPOSE 8080 7077
VOLUME  ["$TFM_LOGS_DIR", "$TFM_METADATA_DIR", "$TFM_DATA_DIR"]
CMD ["/bin/bash"]